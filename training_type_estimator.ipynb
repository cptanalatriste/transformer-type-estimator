{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Language-Based Type Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate\n",
    "\n",
    "* For code change detection\n",
    "* Seeing log messages inside the notebook\n",
    "* Checking TensorFlow configuration.\n",
    "* Setting random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:12.382762: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-28 11:29:12.458493: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-28 11:29:12.809822: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-28 11:29:12.809861: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-28 11:29:12.809865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "INFO:root:Tensorflow version 2.11.0\n",
      "2022-12-28 11:29:13.221254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-28 11:29:13.235328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-28 11:29:13.235455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO:root:Devices available: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "INFO:root:Starting analysis...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "SEED: int = 42\n",
    "\n",
    "import logging\n",
    "logger: logging.Logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "logging.info(f\"Tensorflow version {tf.__version__}\")\n",
    "logging.info(f\"Devices available: {tf.config.list_physical_devices()}\")\n",
    "\n",
    "logging.info(\"Starting analysis...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Checking label counts on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot: xlabel='will_help', ylabel='count'>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "TRAINING_DATA_CSV_FILE = \"data/training_data.csv\"\n",
    "training_dataset: pd.DataFrame = pd.read_csv(TRAINING_DATA_CSV_FILE)\n",
    "validation_dataset: pd.DataFrame\n",
    "training_dataset, validation_dataset = train_test_split(training_dataset, test_size=0.5)\n",
    "\n",
    "sns.countplot(x=\"will_help\", data=training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks\n",
    "\n",
    "Let's train on a single sample, to verify data loading is working fine. We expect perfect accuracy after a few iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_analyser import TransformerTypeAnalyser\n",
    "\n",
    "type_analyser: TransformerTypeAnalyser = TransformerTypeAnalyser(epochs=5)\n",
    "# type_analyser.train(training_dataset.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a single sample, we now train over a very small dataset. Again, we expect perfect accuracy after a few iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:1    3\n",
      "0    2\n",
      "Name: will_help, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "small_sample: pd.DataFrame\n",
    "_, small_sample = train_test_split(training_dataset, test_size=0.07, stratify=training_dataset[\"will_help\"])\n",
    "\n",
    "logging.info(small_sample[\"will_help\"].value_counts())\n",
    "type_analyser = TransformerTypeAnalyser(epochs=10)\n",
    "# type_analyser.train(small_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Training and validating with holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting training...\n",
      "2022-12-28 11:29:14.497411: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-28 11:29:14.498477: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-28 11:29:14.498762: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-28 11:29:14.498926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-28 11:29:14.802729: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-28 11:29:14.802855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-28 11:29:14.802931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-28 11:29:14.803007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14237 MB memory:  -> device: 0, name: NVIDIA RTX A5000 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-12-28 11:29:15.544309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:root:Model compiled...\n",
      "INFO:root:Encoding text ...\n",
      "/home/cgc87/anaconda3/envs/tf/lib/python3.9/site-packages/transformers/generation/tf_utils.py:446: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...bert\n",
      "......embeddings\n",
      ".........LayerNorm\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      ".........dropout\n",
      "............vars\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "............2\n",
      "......encoder\n",
      ".........layer\n",
      "............tf_bert_layer\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_1\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_10\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_11\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_2\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_3\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_4\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_5\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_6\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_7\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_8\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_9\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      ".........vars\n",
      "......pooler\n",
      ".........dense\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      ".........vars\n",
      "......vars\n",
      "...classifier\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...dropout\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "metadata.json                                  2022-12-28 11:29:16           64\n",
      "variables.h5                                   2022-12-28 11:29:16    438401480\n",
      "config.json                                    2022-12-28 11:29:16         2076\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7aa2e73e93f470184bfa481bc4f4062"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...bert\n",
      "......embeddings\n",
      ".........LayerNorm\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      ".........dropout\n",
      "............vars\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "............2\n",
      "......encoder\n",
      ".........layer\n",
      "............tf_bert_layer\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_1\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_10\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_11\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_2\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_3\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_4\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_5\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_6\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_7\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_8\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_9\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      ".........vars\n",
      "......pooler\n",
      ".........dense\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      ".........vars\n",
      "......vars\n",
      "...classifier\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...dropout\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "metadata.json                                  2022-12-28 11:29:17           64\n",
      "variables.h5                                   2022-12-28 11:29:17    438401480\n",
      "config.json                                    2022-12-28 11:29:17         2076\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f21ff522cb34be1a9446de488d4f819"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Encoding finished. Starting training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:30.933805: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f2094010ad0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-28 11:29:30.933824: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA RTX A5000 Laptop GPU, Compute Capability 8.6\n",
      "2022-12-28 11:29:30.936854: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-12-28 11:29:31.022371: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-28 11:29:31.023246: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2022-12-28 11:29:31.023257: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:237] Used ptxas at ptxas\n",
      "2022-12-28 11:29:31.023697: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2022-12-28 11:29:31.067433: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-28 11:29:31.110059: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-28 11:29:31.154024: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-28 11:29:31.331423: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-28 11:29:39.502622: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-28 11:29:39.559661: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-28 11:29:39.609221: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/8 [======>.......................] - ETA: 2s - loss: 0.6970 - sparse_categorical_accuracy: 0.4375  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:40.259264: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8 [==========>...................] - ETA: 1s - loss: 0.7442 - sparse_categorical_accuracy: 0.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:40.597249: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8 [==============>...............] - ETA: 1s - loss: 0.7240 - sparse_categorical_accuracy: 0.4062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:40.932391: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8 [=================>............] - ETA: 1s - loss: 0.7179 - sparse_categorical_accuracy: 0.4500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:41.271985: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8 [=====================>........] - ETA: 0s - loss: 0.6950 - sparse_categorical_accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:41.609360: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.6944 - sparse_categorical_accuracy: 0.4762"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:42.258975: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 26s 720ms/step - loss: 0.6944 - sparse_categorical_accuracy: 0.4762 - val_loss: 0.5948 - val_sparse_categorical_accuracy: 0.8254\n",
      "Epoch 2/15\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.5540 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:45.302813: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8 [==============>...............] - ETA: 1s - loss: 0.5371 - sparse_categorical_accuracy: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:46.320879: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8 [=====================>........] - ETA: 0s - loss: 0.5100 - sparse_categorical_accuracy: 0.9583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:46.983143: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8 [=========================>....] - ETA: 0s - loss: 0.4999 - sparse_categorical_accuracy: 0.9643"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:47.326315: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 494ms/step - loss: 0.5114 - sparse_categorical_accuracy: 0.9365 - val_loss: 0.4728 - val_sparse_categorical_accuracy: 0.8889\n",
      "Epoch 3/15\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.4316 - sparse_categorical_accuracy: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:49.092199: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8 [==========>...................] - ETA: 1s - loss: 0.3767 - sparse_categorical_accuracy: 0.9583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:49.767660: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8 [==============>...............] - ETA: 1s - loss: 0.3602 - sparse_categorical_accuracy: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:50.104743: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8 [=================>............] - ETA: 1s - loss: 0.3412 - sparse_categorical_accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:50.441399: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3336 - sparse_categorical_accuracy: 0.9464"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:51.114958: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 480ms/step - loss: 0.3285 - sparse_categorical_accuracy: 0.9524 - val_loss: 0.3901 - val_sparse_categorical_accuracy: 0.8413\n",
      "Epoch 4/15\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.2017 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:52.790902: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8 [==========>...................] - ETA: 1s - loss: 0.1984 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:53.462975: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8 [=================>............] - ETA: 1s - loss: 0.1848 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:54.140079: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 492ms/step - loss: 0.1708 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3551 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 5/15\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.1353 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:56.567211: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8 [=====================>........] - ETA: 0s - loss: 0.0959 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:58.250568: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0931 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:29:58.594597: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 486ms/step - loss: 0.0905 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3399 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 6/15\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.0631 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:30:00.638995: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8 [==========>...................] - ETA: 1s - loss: 0.0584 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:30:00.977225: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8 [==============>...............] - ETA: 1s - loss: 0.0572 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:30:01.321787: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8 [=================>............] - ETA: 1s - loss: 0.0561 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:30:01.655279: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0536 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:30:02.361975: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 468ms/step - loss: 0.0520 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3453 - val_sparse_categorical_accuracy: 0.8730\n",
      "Epoch 7/15\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.0351 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:30:05.257119: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 466ms/step - loss: 0.0329 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3735 - val_sparse_categorical_accuracy: 0.8730\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0222 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:30:09.848088: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 464ms/step - loss: 0.0222 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4037 - val_sparse_categorical_accuracy: 0.8730\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 4s 465ms/step - loss: 0.0167 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4255 - val_sparse_categorical_accuracy: 0.8730\n",
      "Epoch 10/15\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.0128 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:30:15.703750: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8 [=================>............] - ETA: 1s - loss: 0.0132 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:30:16.042259: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.0125 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 11:30:17.022475: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 5.\n",
      "8/8 [==============================] - 4s 479ms/step - loss: 0.0125 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4431 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 10: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model and Tokenizer saved at ./model\n"
     ]
    }
   ],
   "source": [
    "type_analyser = TransformerTypeAnalyser(epochs=15, batch_size=8, learning_rate=3e-5)\n",
    "type_analyser.train(training_data=training_dataset, testing_data=validation_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
