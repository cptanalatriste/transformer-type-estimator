{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training the Language-Based Type Estimator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Boilerplate\n",
    "\n",
    "* For code change detection\n",
    "* Seeing log messages inside the notebook\n",
    "* Checking TensorFlow configuration.\n",
    "* Setting random seeds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:37:58.073476: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-23 15:37:58.157591: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-23 15:37:58.535598: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-23 15:37:58.535641: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-23 15:37:58.535645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "INFO:root:Tensorflow version 2.11.0\n",
      "2022-12-23 15:37:58.969127: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO:root:Devices available: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2022-12-23 15:37:58.985543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-23 15:37:58.985675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO:root:Starting analysis...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "SEED: int = 42\n",
    "\n",
    "import logging\n",
    "logger: logging.Logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "logging.info(f\"Tensorflow version {tf.__version__}\")\n",
    "logging.info(f\"Devices available: {tf.config.list_physical_devices()}\")\n",
    "\n",
    "logging.info(\"Starting analysis...\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Exploration\n",
    "\n",
    "Checking label counts on the training dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot: xlabel='will_help', ylabel='count'>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "TRAINING_DATA_CSV_FILE = \"data/training_data.csv\"\n",
    "training_dataset: pd.DataFrame = pd.read_csv(TRAINING_DATA_CSV_FILE)\n",
    "validation_dataset: pd.DataFrame\n",
    "training_dataset, validation_dataset = train_test_split(training_dataset, test_size=0.5)\n",
    "\n",
    "sns.countplot(x=\"will_help\", data=training_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sanity Checks\n",
    "\n",
    "Let's train on a single sample, to verify data loading is working fine. We expect perfect accuracy after a few iterations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from transformer_analyser import TransformerTypeAnalyser\n",
    "\n",
    "type_analyser: TransformerTypeAnalyser = TransformerTypeAnalyser(epochs=5)\n",
    "# type_analyser.train(training_dataset.head(1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instead of a single sample, we now train over a very small dataset. Again, we expect perfect accuracy after a few iterations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:1    3\n",
      "0    2\n",
      "Name: will_help, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "small_sample: pd.DataFrame\n",
    "_, small_sample = train_test_split(training_dataset, test_size=0.07, stratify=training_dataset[\"will_help\"])\n",
    "\n",
    "logging.info(small_sample[\"will_help\"].value_counts())\n",
    "type_analyser = TransformerTypeAnalyser(epochs=10)\n",
    "# type_analyser.train(small_sample)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model\n",
    "Training and validating with holdout data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting training...\n",
      "2022-12-23 15:38:00.227248: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-23 15:38:00.227726: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-23 15:38:00.227872: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-23 15:38:00.227945: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-23 15:38:00.560675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-23 15:38:00.560814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-23 15:38:00.560899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-23 15:38:00.560984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14237 MB memory:  -> device: 0, name: NVIDIA RTX A5000 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-12-23 15:38:01.276597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:root:Model compiled...\n",
      "INFO:root:Encoding text ...\n",
      "/home/cgc87/anaconda3/envs/tf/lib/python3.9/site-packages/transformers/generation/tf_utils.py:446: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...bert\n",
      "......embeddings\n",
      ".........LayerNorm\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      ".........dropout\n",
      "............vars\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "............2\n",
      "......encoder\n",
      ".........layer\n",
      "............tf_bert_layer\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_1\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_10\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_11\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_2\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_3\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_4\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_5\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_6\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_7\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_8\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_9\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      ".........vars\n",
      "......pooler\n",
      ".........dense\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      ".........vars\n",
      "......vars\n",
      "...classifier\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...dropout\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.fingerprint:Parameter 'function'=<bound method TransformerTypeAnalyser.tokenize of <transformer_analyser.TransformerTypeAnalyser object at 0x7f38c0864bb0>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73956149226e49bb9568ebb7fceac19b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...bert\n",
      "......embeddings\n",
      ".........LayerNorm\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      ".........dropout\n",
      "............vars\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "............2\n",
      "......encoder\n",
      ".........layer\n",
      "............tf_bert_layer\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_1\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_10\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_11\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_2\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_3\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_4\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_5\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_6\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_7\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_8\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      "............tf_bert_layer_9\n",
      "...............attention\n",
      "..................dense_output\n",
      ".....................LayerNorm\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dense\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................vars\n",
      "..................self_attention\n",
      ".....................dropout\n",
      "........................vars\n",
      ".....................key\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................query\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................value\n",
      "........................vars\n",
      "...........................0\n",
      "...........................1\n",
      ".....................vars\n",
      "..................vars\n",
      "...............bert_output\n",
      "..................LayerNorm\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................vars\n",
      "...............intermediate\n",
      "..................dense\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............vars\n",
      ".........vars\n",
      "......pooler\n",
      ".........dense\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      ".........vars\n",
      "......vars\n",
      "...classifier\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...dropout\n",
      "......vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c9b46cab1e540829b3dca603365ef69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Encoding finished. Starting training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:16.477484: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x55b8c3c6c3d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-23 15:38:16.477502: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA RTX A5000 Laptop GPU, Compute Capability 8.6\n",
      "2022-12-23 15:38:16.480677: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-12-23 15:38:16.527967: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-23 15:38:16.528925: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2022-12-23 15:38:16.528931: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:237] Used ptxas at ptxas\n",
      "2022-12-23 15:38:16.529426: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2022-12-23 15:38:16.570995: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-23 15:38:16.615862: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-23 15:38:16.660134: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-23 15:38:16.847299: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-23 15:38:25.451973: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-23 15:38:25.505977: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-12-23 15:38:25.605980: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/8 [======>.......................] - ETA: 2s - loss: 0.7936 - sparse_categorical_accuracy: 0.3750  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:26.261443: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8 [==========>...................] - ETA: 1s - loss: 0.7783 - sparse_categorical_accuracy: 0.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:26.594633: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8 [==============>...............] - ETA: 1s - loss: 0.7576 - sparse_categorical_accuracy: 0.4062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:26.926838: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8 [=================>............] - ETA: 1s - loss: 0.7182 - sparse_categorical_accuracy: 0.5250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:27.261191: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8 [=====================>........] - ETA: 0s - loss: 0.7126 - sparse_categorical_accuracy: 0.5208"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:27.596672: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.7233 - sparse_categorical_accuracy: 0.4762"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:28.238765: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 28s 795ms/step - loss: 0.7233 - sparse_categorical_accuracy: 0.4762 - val_loss: 0.6514 - val_sparse_categorical_accuracy: 0.6984\n",
      "Epoch 2/25\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.5858 - sparse_categorical_accuracy: 0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:31.831562: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8 [==============>...............] - ETA: 1s - loss: 0.5765 - sparse_categorical_accuracy: 0.8125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:32.833380: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8 [=====================>........] - ETA: 0s - loss: 0.5439 - sparse_categorical_accuracy: 0.8542"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:33.497578: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8 [=========================>....] - ETA: 0s - loss: 0.5331 - sparse_categorical_accuracy: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:33.830281: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 475ms/step - loss: 0.5336 - sparse_categorical_accuracy: 0.8730 - val_loss: 0.5194 - val_sparse_categorical_accuracy: 0.8413\n",
      "Epoch 3/25\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.3657 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:35.486824: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8 [==========>...................] - ETA: 1s - loss: 0.3501 - sparse_categorical_accuracy: 0.9583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:36.165569: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8 [==============>...............] - ETA: 1s - loss: 0.3471 - sparse_categorical_accuracy: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:36.519444: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8 [=================>............] - ETA: 1s - loss: 0.3391 - sparse_categorical_accuracy: 0.9750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:36.841581: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8 [=========================>....] - ETA: 0s - loss: 0.3421 - sparse_categorical_accuracy: 0.9464"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:37.516012: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 471ms/step - loss: 0.3400 - sparse_categorical_accuracy: 0.9365 - val_loss: 0.5271 - val_sparse_categorical_accuracy: 0.7302\n",
      "Epoch 4/25\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.2311 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:39.114859: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8 [==========>...................] - ETA: 1s - loss: 0.1859 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:39.786841: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8 [=================>............] - ETA: 1s - loss: 0.1801 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:40.454888: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 475ms/step - loss: 0.1780 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3710 - val_sparse_categorical_accuracy: 0.8413\n",
      "Epoch 5/25\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.1253 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:42.777287: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8 [=====================>........] - ETA: 0s - loss: 0.0948 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:44.445088: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0920 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:44.785082: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 459ms/step - loss: 0.0897 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3939 - val_sparse_categorical_accuracy: 0.8413\n",
      "Epoch 6/25\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 0.0692 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:46.657533: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/8 [==========>...................] - ETA: 1s - loss: 0.0645 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:46.990830: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8 [==============>...............] - ETA: 1s - loss: 0.0625 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:47.323947: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8 [=================>............] - ETA: 1s - loss: 0.0603 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:47.660070: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0567 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:48.326848: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 459ms/step - loss: 0.0566 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4605 - val_sparse_categorical_accuracy: 0.7937\n",
      "Epoch 7/25\n",
      "5/8 [=================>............] - ETA: 1s - loss: 0.0474 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:51.212538: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 460ms/step - loss: 0.0423 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3838 - val_sparse_categorical_accuracy: 0.8730\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0264 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:38:55.742916: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 460ms/step - loss: 0.0264 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3770 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 4s 460ms/step - loss: 0.0191 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4027 - val_sparse_categorical_accuracy: 0.8413\n",
      "Epoch 10/25\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.0167 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:39:01.541070: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8 [=================>............] - ETA: 1s - loss: 0.0165 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:39:01.877146: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.0157 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:39:02.864761: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 462ms/step - loss: 0.0157 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4276 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 11/25\n",
      "1/8 [==>...........................] - ETA: 2s - loss: 0.0149 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:39:04.108370: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/8 [=================>............] - ETA: 1s - loss: 0.0127 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:39:05.448381: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/8 [=====================>........] - ETA: 0s - loss: 0.0122 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:39:05.786133: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 463ms/step - loss: 0.0118 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4471 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 12/25\n",
      "4/8 [==============>...............] - ETA: 1s - loss: 0.0101 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:39:08.694519: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/8 [=========================>....] - ETA: 0s - loss: 0.0097 - sparse_categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 15:39:09.700255: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.0097 - sparse_categorical_accuracy: 1.0000Restoring model weights from the end of the best epoch: 4.\n",
      "8/8 [==============================] - 4s 476ms/step - loss: 0.0097 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4622 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 12: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model and Tokenizer saved at ./model\n"
     ]
    }
   ],
   "source": [
    "type_analyser = TransformerTypeAnalyser(epochs=5, batch_size=8)\n",
    "type_analyser.train(training_data=training_dataset, testing_data=validation_dataset)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
